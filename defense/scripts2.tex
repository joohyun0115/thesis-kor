%Introduce
Good afternoon, Ladies and gentlemen. 
It's a great pleasure to be with you today.
My name's Joohyun Kyong and I'm a Phd Student at Kookmin University.

I know some of you have come a long way today so I aim to make your tour both 
interesting and worthwhile.

This afternoon I'd like to talk about 'LDU:A Lightweight concurrent update
method with deferred processing for Linux kernel Scalability'.
My talk will last about 10 minutes.

%Outline 
What I intend to do is to break down this presentation into four parts: 
First, I'll describe Linux scalability history, reviewing some of the early
studies and their technical issues.
Then I'll talk about what is scalability problem.
In particular, I'll describe what is the academic problem in Linux kernel.
Then I'll show you our new method, so I'll share with you some of the
improved point taken from several measureements. 
Finally, I'll make a brief summary and future plans.

There's quite a lot to cover, so I'd be grateful if you'd hold any questions
until the end of my talk.

%40 Years of Microprocessor Trend Data
First, I'll describe some of the background research.
As you all know, 40 years of microprocessor trend data have two interesting
things.
First, single-thread performance has kept increasing slightly, 
reflecting that this is still an important quantity. 
Second, the number of cores is now increasing with a power law, so you 
know that Amdahl's Law requires us to use parallel algorithms. 

%History of the Linux scalability research
Now we come to the next, I will make a brief history of Linux
scalability research.
Let me refresh your memory on the history of the Linux Scalability research,
published by Dr Wickizer at the MIT University in 2010s. 
He analyed the scalability of various applications such as Exim, Apache, and
MapReduce.
Especially, he was running on Linux on a 48 core computer.
As you all know, he has succeeded in improving pretty much everything that you
can think of.
Similarly, Dr Clements, from the same lab, contributes the linux scalability
using the RCU in terms of the single address space.
He succeeded in the read-mostly lock contention problem.
Thanks to these efforts, the Linux kernel has considerably improved the
scalability in the read-mostly situation, which were great.

%What about update? In the Linux
But, What about update? Let's go on to the next.
Please turn your attention to the next page, you will see the graph.
Indeed, this graph was generated by our research team.
AIM7 is very famous linux scalailby benchmark and it has Linux fork-intencive
worklad.
The AIM7 multiuser is composed of various workload such as disk-file operations,
process creation, virtual memory opertions, pipe, and arithmetic operation.
We run on 120 core system with tmpfs filesystems because minimize IO bottlnecks.
Since y axis shows the throuput, the hight line represents the better
performance and the x axis shows number of cpu.
Up to 60 core, the stock Linux scales linearly, but then they flattens out.
Indeed, idle Scalability is like this.
However, real Linux scales flattens out.

%Lock profile on the 120 core
In order to understand this problem, we profie the lock on the 120core using the
Linux lockstat profiler.

%Lockstat
We found the two lock problem. The one is anon_vma->rwsem, the other is mapping
file rwsem, both of which are called by Linix fork processing.
Furthermore, both locks are update locks.
It means that serialized update during fork is problem in Linux kernel.

%Update serialized
As you can see, Updates cann't run on the same time as an exclusive lock even
using the reader-writer locks or RCU.
Here, anon_vma->rwsem and i_mmap are updates.

%Exsistence Solution - 1
Do you know what is the best solution for update serialization?
Don't do update is best solution.
That measns moving the update moslty data structure to read-moslty data
structure.
But everything can not be applied to move the read-mostly data structure 
such as reverse mapping that is update-mostly data structure.

The other exsting solution is using the non-blocking algorithms such as
lock-free or wait-free data structure base on compare-and-swap operation.
However, this data structure incurs additional issues because
inter-core communication bottlenecks and cache coherence system's write
serialization.

%Exsistence Solution - 2
The second solution is the per-CPU approach.
Basically, Per-CPU processing may makes great scalability about update-heavily
data structure.
For example, suppose that you need to collect statistics on the number of
networking packets.
A separate thread is provided to transfer counts from the per-thread counters
to the global counter.
Readers simply access the value of the global counter.
Generally, Per-CPU approach gives extremely fast for update-heavily.
Currently, this method, However, can be just applying the simple counters.
If you apply into list operation, per-core approach may needs to additional
behavior such as save timestamp and save operation and then merging of the
update logs in cronozilal order that recored in multiple per-core data. 
Therefore, it do complex that reader before operations. 
This is basic background of my research.

%LDU
So, for now, we focus on our lightweight concurrent update approach.
LDU is similar to Oplog becasue it defers the actual update operations as late
as possible to reduce serialization problems.
However, LDU can eliminates time stamps.
Time stamps based approach required for per-core log
managements.

Here is an example of our solution.
We give an example of deferred update a with six update operations and
one read operation.

Initially, the data structure for physical updata is a tree, and values
in the tree are node A and B.
On the other hand, the data structure for logical update is lock-less list.

Core0, Core1 and Core2 perform the
logical insert operation to nodes C, D and E, respectively.

The logical inserts set the insert mark, and they then insert their
nodes into lock-less list.

In this case, none of the lock is needed because LDU uses the lock-less
list;all threads can execute the update concurrently.
Similarly, node D, E insert lock less list with marking operation.

At T1, the tree contains node A and B and the lock-less list contains node
E, D and C.

When removing the node C, the node C, whose mark field was marked
by insert, LDU cleans up the insert marked field.
We call that update-side absorbing.

Becasue node A is first time, it marks r-mark feild and
then node A insert lock-list.

Therefore, At T2, the lock-less list contains nodes A, E, D, and C, and the
marking field is zero for nodes E and C.

Before running the synchronize function, LDU need to lock the original tree's
lock using the exclusive lock in order to protect the tree's operation.

The synchronize migrates from lock-less list node to tree node, each of 
which is the marked node, so nodes D and A are migrated.

Finally, the tree contains nodes D and B, so the reader can read eventually
consistent data.

That brings us to the last phase.

%AIM7
We implemented the new deferred update algorithm in Linux 3.19.rc4 kernel.
We compare our LDU implementation to a concurrent non-blocking Harris linked
list.

Up to 60 core, the stock Linux scales linearly while serialized updates in
Linux kernel become bottlenecks.
 
However, up to 120core, unordered harris list and our LDU scale well because
these workloads can run concurrently updates and can reduce the locking
overheads due to reader-writer semaphores anon_vma, file).

The combination of LDU with unordered harris list has best performance and
scalability outperforming stock Linux.

While the unordered harris list has 19 idle time stock Linux has 51 idle time
 waiting to acquire both anon_vma's rwsem and file's i_mmap_rwsem.

We can notice that although LDU has 23 idle time, the throughput is higher
than unordered harris list, so LDU is more power efficient.


%Summary
That brings me to the end of my presentation. 
I sincerely hope you'll all go away with a more complete picture of the
scalability issue of the Linux kernel.
Let me just run over the key points again and just summarize the main issues as
I see them.

Firstly, on the history of Linux scalability, what was the problem and how
they can be solved.
Secondly, the reverse mapping's update lock is the main problem in our research.
Thirdly, I describeed LDU, a Lightweight concurrent update
method with deferred processing, and I shared with you evaluation of LDU.
Finally, I summarize my research paper and future plan. 
Actually, the Linux kernel has other update havy data structure.
So, I aim to make a our new method apply to other data structure.

LDU is implemented on to Linux kernel 3.19 and available as open-source from
github.

Thank you for listening.

I'd be glad to try and answer any questions. 

Questions:
