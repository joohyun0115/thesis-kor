\section{서론} \label{sec:introduction}

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Background
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

최근 코어수가 증가하고 있다.
이처럼 100개 이상 코어수가 증가한 매니코어 환경에서 리눅스 커널에 대한 확장성 문제가 있다. 
확장성 문제 중 하나가 락 경합 때문에 발생하는 serialization 문제이다.
여러 락 serialization 문제 중 하나가 update operation이기 때문에 발생하는 문제가 있다. 그 이유는
update operation 는 동시에 수행되지 못하기 때문이다.
리눅스 커널의 reverse page mapping이 update rate가 높은 구조로 되어 있다.
따라서 리눅스 커널의 rmap update lock에 때문에 serialize 되어 scalability 문제가 있다.


이처럼 update serialization 문제를 해결하기 위해 여러 concurrent updates 방법[][][] 들이 연구되고
있다. 
이러한 concurrent updates 방법들은 워크로드 특성인 update ratio에 따라 많은 성능 차이를 보인다.
이 중 high update ratio를 가진 커널의 rmap과 같이 update-heavy한 data structure일 경우, 이를
해결하기 위한 방법 중 하나는 log-based 알고리즘[][][]을 사용하는 것이다. 
log-based 알고리즘은 ~~~~ 이며, 마치 CoW와 유사한 방법을 사용한다. 
Silas Boyd-Wickizer ,. update heavy한 구조를 timestamp 기반의 per-core log를 활용한
방법을 제안하였다.
timestamp 기반의 per-core log를 활용한 concurrent updates 방법은 update 부분만
고려했을 때 굉장히 좋은 scalability를 가지고 있다. 하지만 timestamp 관리 비용에 대한 문제가 있다.
다시 말하면, core가 늘어 날 수로 timestamp 관리하는 비용기 커진다. 
예를 들어 코어 수가 1000개로 늘어 날 경우 log를 merge하는 reader가 각 코어에 쌓인 log를 시간 순서로 정렬하고
관리하는 비용이 커진다.
또한 per-core로 log를 저장하는 공간에 대해서도 고려해야한다. OpLog는 per-core hash table로 root 포인터를
가지고 있는 object의 log를 bucket단위로 저장하는데, 만약 root의 object 많은 경우, 잦은 hash
충돌로 인한 문제가 발생한다.


%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Method
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
`



%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Mapping
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$






%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
% Reference Sentence 1
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$






%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Reference Sentence 2:LDU paper
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
% Ondemand로 로그를 지워 준다.
%Background
%With the drastic increase of CPU core counts in various high-end
%server systems, achieving performance scalability of operating systems
%running on such many-core systems has been an important issue in research
%communities.
%Linux has been naturally considered as a major target for the scalability
%improvement and a number of accomplishments are published.
%Early results include RCU~\cite{McKenney98} and hazard
%pointer~\cite{MagedMichael04a} to improve scalability for read-most data 
%structures in the Linux kernel. %for relatively low CPU core counts.
%Though the early results show certain level of improvement in scalability,
%it turned out that more significant portion of scalability limitation of
%Linux kernel is due to lock contention in update-heavy global data structures 
%including file reverse mappings and anonymous reverse mappings during
%spawning child processes~\cite{Andi2011adding}~\cite{Tim2013adding}. 
%Such update-heavy data structures cause serialization of the update operations
%leading to severe performance degradation. 

%Scaling operating systems to many-core architectures is one of the most
%important challenges in computing today. 
%One of the scalable operations system is Linux because the Linux kernel
%community has made it scalable.
%For example, read-mostly data structures in the Linux have been achieved
%considerable multi-core scaling by using RCU~\cite{McKenney98} and hazard
%pointer~\cite{MagedMichael04a}.
%However, the Linux kernel suffers from such scalability bottlenecks at high
%core counts.
%The Linux kernel on many-core processors can be
%bottlenecked by contended updates locks where processes share a global data
%structure.
%When a process spawns child process, reverse mapping using shared global
%data structure suffers from updates lock contention.
%Recent research shows how to run a fork in parallel with creating new reverse
%mapping data structure~\cite{SilasBoydWickizerPth}.
%More specifically, in order to perfect scalability of the fork, both the
%file reverse mapping and the anonymous reverse mapping can execute
%update concurrently without lock
%contention~\cite{Andi2011adding}~\cite{Tim2013adding}.

%The fundamental scalability problem of reverse mapping is their serialized
%update because operating systems are serialized at the update operation.

%To solve this problem, an existing approach is to make the update-heavy data
%structures as non-blocking~\cite{Harris2001Lockfree} based on
% \emph{compare-and-swap}(CAS).
%Introducing non-blocking data structures eliminates the update serialization
% problem during process spawning, but incurs additional issues due to
% inter-core communication
%bottlenecks and cache coherence system's write
% serialization~\cite{SilasBoydWickizerPth}.
%To overcome the issues caused by cache coherence system, S. Boyd-Wickizer et
% al. proposed Oplog~\cite{SilasBoydWickizerPth} where logs update operations
% with time stamps and actual updates are performed later when the updated data
% need to be read.
%While Oplog nicely solves the update serialization problem without any cache
% coherence-related overheads, the merging of the update logs recorded in
% multiple per-core data structures considering time stamps further causes
% performance overheads resulting in limited scalability
% improvement~\cite{McKenney2008ParallelProgramming}.

%Therefore, many researches have proposed non-blocking
%algorithms~\cite{Harris2001Lockfree} for concurrent data structure based on
%\emph{compare-and-swap}(CAS);nonetheless, this method may suffer from inter-core
%communication bottleneck, the cache coherence system serializes the
% writes~\cite{SilasBoydWickizerPth}.

%Another a existing solution is using the per-core processing like
%Oplog~\cite{SilasBoydWickizerPth}, which achieves scalability by logging in
%per-core memory.
%In fact, per-core approach may have best performance for the update-heavy data
%structure because of their partitioned data structures, whose updates can
%operate locally.
%The more-expensive reads, however, must merge across the entire per-core
%data;read operations are expensive~\cite{McKenney2008ParallelProgramming}.
%Therefore, their approach may be complex with regard to the read operation.
%This paper attacks this complexity as a result of the per-core processing.
%Even though they have generalized a per-core processing to the Oplog's library, 
%they use intricate optimizations, so their optimizations may be expensive with
%regard to the read operation.
%For example, they use the absorbing updates that removes the cancelable
%operation before the read.
%This operation may need to iterate previous operation log due to searching the
%cancelable operation log.
%Furthermore, reducing the memory use, they maintain per-core memory space.

%Method
%This paper proposes a novel concurrent update method, \deferu, applicable to
% Linux reverse mapping solving the problems 
%mentioned above: the overheads caused by inter-core communication bottlenecks
% and per-core log management with time stamps. 
%Our goal is to make the Linux fork scale to large numbers of cores using
%lightweight deferred processing algorithm.
%The fork scalability requires two challenges in designing a reverse mapping.
%First, this lightweight method should permit the concurrent updates not only to
%reduce the inter-core communication bottleneck but also to eliminate their 
%complexity.
%Second, this lightweight method should apply to Linux reverse mapping, and
%improve the Linux fork scalability.

%The \deferu is similar to Oplog in that it defers the actual update operations
% as late as possible to reduce serialization problems, but it uses a light
% weight global queue with non-blocking synchronization for update logs and
% eliminates time stamps required for per-core log management. 
%In addition, to optimize the log management and minimize the traversal
% overheads during reading, \deferu applies update-side absorbing algorithm based on atomic
%marking and thus efficiently find the operations to be canceled. 
%The evaluation of the proposed \deferu on Linux kernel 3.19.rc4 running on a
% 120 core system reveals that 
%the execution times could be improved by 1.7x, 1.6x, and 2.2x for 
%a fork-intensive workload-
%AIM7~\cite{AIM7Benchmark}, Exim from
%MOSBENCH~\cite{SilasBoydWickizer2010LinuxScales48}, and 
%lmbench~\cite{mcvoy1996lmbench}, respectively.

%Second, it uses a novel update-side absorbing that uses the atomic marking
%method, which allows \deferu to eliminate read-side traversal for finding the
%cancelable operation log;readers can improve performance.

%The proposed approach has the following advantages. 
%First, it can permits the reverse mapping to remove lock contention, so Linux's
%fork scalability has been improved.
%Second, using the lightweight update-side absorbing, \deferu can reduce
%complexity and improve readers performance.
%Finally, while per-core processing uses the time-stamp counter(e.g., RDTSCP,
%RDTSC) that depend on hardware, our method may not depend on hardware.

%We implemented the \deferu in a Linux 3.19.rc4 with modification of lock. 
%We evaluated the performance and scalability using a fork-intensive workload-
%AIM7~\cite{AIM7Benchmark}, Exim from
%MOSBENCH~\cite{SilasBoydWickizer2010LinuxScales48},
%lmbench~\cite{mcvoy1996lmbench}-our design improves throughput and execution
%time on 120 core by 1.7x, 1.6x, 2.2x respectively, relative to stock Linux.

%Mapping
%Paragraph 
%This paper is organized as follows. 
%Section 2 summarizes related works and compare our contributions to previous
%works. 
%Section 3 describes the design of the \deferu algorithm and 
%Section 4 explains how to apply to Linux kernel.
%section 5 explains our implementations in Linux and
%Section 6 shows the results of the experimental evaluation. 
%Finally, section 7 concludes the paper.
